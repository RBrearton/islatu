{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################################################ #\n",
    "# THE FOLLOWING CELL IS REQUIRED ONLY TO TEST LOCAL UNBUILT VERSIONS OF ISLATU\n",
    "# ############################################################################ #\n",
    "# Necessary to reload islatu when making changes to a local version.\n",
    "import importlib\n",
    "from os import chdir\n",
    "\n",
    "chdir(\"/Users/richardbrearton/Documents/Code/islatu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Uncomment to see what <autoreload 2> is doing.\n",
    "# %autoreload?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need some preliminary setup.\n",
    "# We will need a list of the paths to the data files.\n",
    "data_dir = \"/Users/richardbrearton/Documents/Data/i07_data/DCD/tom_arnold_data/\"\n",
    "run_numbers = list(range(404875, 404883))\n",
    "data_files = [data_dir + \"i07-\" + str(i) + \".nxs\" for i in run_numbers]\n",
    "\n",
    "# Was this data recorded with the diffractometer in the DCD configuration?\n",
    "is_DCD_data = True\n",
    "\n",
    "if is_DCD_data:\n",
    "    DCD_normalization_file = data_dir + \"404863.dat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to load the data into an Isaltu Profile object.\n",
    "from islatu.profile import Profile\n",
    "\n",
    "# We're loading .nxs files acquired at beamline I07, so we'll need to make use\n",
    "# of Islatu's I07 .nxs parser\n",
    "from islatu.io import i07_nxs_parser\n",
    "import islatu\n",
    "\n",
    "importlib.reload(islatu.profile)\n",
    "importlib.reload(islatu.io)\n",
    "\n",
    "\n",
    "# Note: at this stage, the various detector images will be loaded into RAM.\n",
    "# As reflectometry profiles can contain a large number of high resolution\n",
    "# detector frames, the following line of code may take a long time to execute.\n",
    "profile = Profile.fromfilenames(data_files, i07_nxs_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reflectivity profile is made up of a series of scans, each of which contains\n",
    "# a number of images that we have just loaded into RAM. Now we can plot any of\n",
    "# raw detector frames. Matplotlib is rubbish, so we're going to use plotly for\n",
    "# data visualization. Below is a convenience function that we'll use to render\n",
    "# raw images.\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_array(input_array, imshow_data_map='log', colorscale='Jet'):\n",
    "    \"\"\"\n",
    "    Simple convenience function for plotting detector frames.\n",
    "\n",
    "    Args:\n",
    "        input_array (:py:attr:`array_like`):\n",
    "            An array to be plotted\n",
    "        imshow_data_map (:py:attr:`str`, optional):\n",
    "            A string specifying how input_array will be mapped before it is\n",
    "            displayed. Options are 'log', 'sqrt' and 'linear'.\n",
    "\n",
    "    \"\"\"\n",
    "    # Currently implemented ways to map the input array for the imshow.\n",
    "    imshow_data_maps = {\"linear\": lambda img: np.copy(img),\n",
    "                        \"log\": lambda img: np.log(np.copy(img)+0.1),\n",
    "                        \"sqrt\": lambda img: np.sqrt(np.copy(img))}\n",
    "\n",
    "    # Map the input_array to create the array that will be rendered.\n",
    "    arr_to_display = imshow_data_maps[imshow_data_map](input_array)\n",
    "\n",
    "    fig = make_subplots(rows=3, cols=1, specs=[[{\"type\": \"heatmap\"}],\n",
    "                                               [{\"type\": \"xy\"}],\n",
    "                                               [{\"type\": \"xy\"}]],\n",
    "                        subplot_titles=(\"Raw detector image\",\n",
    "                                        \"Mean value of pixels along x\",\n",
    "                                        \"Mean value of pixels along y\"))\n",
    "\n",
    "    fig.append_trace(go.Heatmap(z=arr_to_display, colorscale=colorscale), \n",
    "        row=1, col=1)\n",
    "\n",
    "    # Average pixel value as a function of x, y\n",
    "    input_array_x_mean = np.mean(input_array, axis=0)\n",
    "    input_array_y_mean = np.mean(input_array, axis=1)\n",
    "\n",
    "    fig.append_trace(go.Scatter(y=input_array_x_mean), row=2, col=1)\n",
    "    fig.append_trace(go.Scatter(y=input_array_y_mean), row=3, col=1)\n",
    "\n",
    "    # Now set the figure title\n",
    "    fig.update_layout(\n",
    "        height=1000, title_text=\"Raw Detector Data\", showlegend=False)\n",
    "\n",
    "    # Update xaxis titles\n",
    "    fig.update_xaxes(title_text=\"Detector x-axis\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"x-pixel\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"y-pixel\", row=3, col=1)\n",
    "\n",
    "    # Update yaxis titles\n",
    "    fig.update_yaxes(title_text=\"Detector y-axis\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Mean intensity\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Mean intensity\", row=3, col=1)\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a function to make grabbing images from our profile as simple as\n",
    "# possible. We could do this in one line, but it would get pretty annoying.\n",
    "\n",
    "def get_image_array(scan_number, img_number):\n",
    "    scan_object = profile.scans[scan_number]\n",
    "    img_object = scan_object.images[img_number]\n",
    "\n",
    "    frame = img_object.n\n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can very simply inspect any of the raw detector images acquired as a\n",
    "# part of our profile.\n",
    "\n",
    "# Enter the scan/image numbers of interest.\n",
    "scan_number = 0\n",
    "img_number = 0\n",
    "\n",
    "# Load the img_array\n",
    "img_array = get_image_array(scan_number, img_number)\n",
    "\n",
    "# How do you want your data to be rescaled for visualization purposes?\n",
    "# Options are: \"log\", \"sqrt\" and \"None\" (None keeps the raw data)\n",
    "imshow_data_map = \"log\"\n",
    "\n",
    "plot_array(img_array, imshow_data_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: auto cropping should go here. \n",
    "\n",
    "# The raw detector frame is typically much larger than the area containing\n",
    "# scattered intensity. As the following operations can be computationally\n",
    "# demanding, it's best to start by cropping the image down to something more\n",
    "# manageable.\n",
    "\n",
    "from islatu.cropping import crop_2d\n",
    "\n",
    "# The pixel coordinates of the corners of the cropped image.\n",
    "x_start = 1150\n",
    "x_end = 1280\n",
    "y_start = 150\n",
    "y_end = 300\n",
    "\n",
    "profile.crop(crop_2d, {\n",
    "            'x_start': profile.scans[0].metadata.roi_1_x1,\n",
    "            'x_end': profile.scans[0].metadata.roi_1_x2,\n",
    "            'y_start': profile.scans[0].metadata.roi_1_y1,\n",
    "            'y_end': profile.scans[0].metadata.roi_1_y2\n",
    "})\n",
    "\n",
    "# Perform the cropping.\n",
    "# profile.crop(crop_2d, {'x_start': x_start, 'x_end': x_end,\n",
    "#                        'y_start': y_start, 'y_end': y_end})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the cropped image; make sure the output looks reasonable. It is not\n",
    "# necessary for the peak to be perfectly centered, but it should be fairly \n",
    "# close.\n",
    "scan_number = 7\n",
    "img_number = 23\n",
    "imshow_data_map = \"linear\"\n",
    "cropped_img_array = get_image_array(scan_number, img_number)\n",
    "cropped_img_array = profile.scans[scan_number].images[img_number].n\n",
    "\n",
    "plot_array(cropped_img_array, imshow_data_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to subtract the background. In an experiment, a user will specify\n",
    "# two regions of interest in GDA. ROI_1 contains the reflected intensity, while\n",
    "# ROI_2 indicates a background region. \n",
    "\n",
    "# Here, will will specify our own ROI_2 so we can play around with it.\n",
    "roi_2 = {'x_start': 1100, 'x_end': 1180,\n",
    "         'y_start': 150, 'y_end': 300}\n",
    "\n",
    "\n",
    "# Or, alternatively, we can access the roi_2 that was set in the experiment.\n",
    "roi_2 = {\n",
    "    'x_start': profile.scans[0].metadata.roi_2_x1,\n",
    "    'x_end': profile.scans[0].metadata.roi_2_x2,\n",
    "    'y_start': profile.scans[0].metadata.roi_2_y1,\n",
    "    'y_end': profile.scans[0].metadata.roi_2_y2\n",
    "}\n",
    "\n",
    "# Carry out the background subtraction.\n",
    "mean_bkg_per_pixel = profile.bkg_sub(None, roi_2)\n",
    "print(mean_bkg_per_pixel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can quickly plot our beam profile to make sure that the background looks\n",
    "# properly subtracted.\n",
    "\n",
    "# Scan and image numbers of interest.\n",
    "scan_number = 7\n",
    "img_number = 23\n",
    "\n",
    "# Get the image array for the scan of interest.\n",
    "arr = get_image_array(scan_number, img_number)\n",
    "arr_along_x = np.mean(arr, axis=0)\n",
    "\n",
    "arr_e = profile.scans[scan_number].images[img_number].array_e\n",
    "arr_e_along_x = np.mean(arr_e, axis=0)\n",
    "\n",
    "# Prepare the figure.\n",
    "title = \"Scan {}, Image {}\".format(scan_number, img_number)\n",
    "fig = go.Figure().update_layout(title=title)\n",
    "fig.add_trace(go.Scatter(y=arr_along_x))\n",
    "fig.add_trace(go.Scatter(y=arr_e_along_x))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !Experimental code cell!\n",
    "# Towards the end of a scan, there's a tendancy for signal to become rather lost\n",
    "# in the noise. We can try to extract more signal by wavelet transforming our\n",
    "# data, setting the high frequency wavelet coefficients to 0 and transforming\n",
    "# back.\n",
    "\n",
    "import pywt\n",
    "\n",
    "# We're just testing, don't mess with the profile yet.\n",
    "arr_along_x_copy = arr_along_x.copy()\n",
    "\n",
    "wavelet_choice = \"sym4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def wavelet_denoise(raw_data, wavelet_choice, threshold):\n",
    "    \"\"\"\n",
    "    A function to perform some simple wavelet denoising on some raw input data.\n",
    "    \"\"\"\n",
    "    w = pywt.Wavelet(wavelet_choice)\n",
    "    maxlev = pywt.dwt_max_level(len(raw_data), w.dec_len)\n",
    "    # maxlev = 2 # Override if desired\n",
    "    print(\"maximum level is \" + str(maxlev))\n",
    "\n",
    "\n",
    "    # Decompose into wavelet components, to the level selected:\n",
    "    coeffs = pywt.wavedec(raw_data, wavelet_choice, level=maxlev)\n",
    "\n",
    "    # first find the largest coefficient\n",
    "    imax, jmax = 0, 0\n",
    "    max_coef = 0\n",
    "    for i in range(1, len(coeffs)):\n",
    "        for j in range(len(coeffs[i])):\n",
    "            if coeffs[i][j] >= max_coef:\n",
    "                max_coef = coeffs[i][j]\n",
    "\n",
    "    print(max_coef)\n",
    "\n",
    "    #cA = pywt.threshold(cA, threshold*max(cA))\n",
    "    plt.figure()\n",
    "    for i in range(0, len(coeffs)):\n",
    "\n",
    "        plt.subplot(maxlev+1, 1, i+1)\n",
    "        plt.plot(coeffs[i])\n",
    "        if i < maxlev:\n",
    "            coeffs[i] = pywt.threshold(coeffs[i], threshold*max_coef)\n",
    "        else:  \n",
    "            # # always kill ultra high frequency nonsense\n",
    "            # coeffs[i] = pywt.threshold(coeffs[i], 1*max_coef)\n",
    "            coeffs[i] = pywt.threshold(coeffs[i], threshold*max_coef)\n",
    "        plt.plot(coeffs[i])\n",
    "\n",
    "    plt.show()\n",
    "    return coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_wav_choice = \"sym4\"\n",
    "wavelet_coeffs = wavelet_denoise(arr_along_x_copy, discrete_wav_choice, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarec = pywt.waverec(wavelet_coeffs, discrete_wav_choice)\n",
    "\n",
    "plt.plot(arr_along_x_copy)\n",
    "plt.show()\n",
    "plt.plot(datarec)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(arr_along_x_copy)\n",
    "plt.plot(datarec)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pywt.wavelist(kind='continuous')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# try a continuous wavelet transform\n",
    "import plotly.express as px\n",
    "wavelet_choice = 'gaus8'\n",
    "scales = np.arange(1, len(arr_along_x_copy))\n",
    "#scales = np.array([1, 2, 4, 8, 16, 32, 64, 128, 256, 512])\n",
    "\n",
    "coef, freqs = pywt.cwt(arr_along_x_copy, scales, wavelet_choice)\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=np.abs(coef))])\n",
    "\n",
    "fig.update_layout(title='Continuous wavelet ({}) transform'.format(\n",
    "    wavelet_choice), \n",
    "                  autosize=False,\n",
    "                  width=1000, height=1000,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This'll come in handy for plotting the various XRR curves we come across.\n",
    "\n",
    "def plot_xrr_curve(refl_profile, title, is_log=True):\n",
    "    \"\"\"\n",
    "    Convenience function for plotting simple XRR curves.\n",
    "    \"\"\"\n",
    "    fig = go.Figure().update_layout(title=title,\n",
    "                                    xaxis_title='Q/Å', yaxis_title='R')\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=(profile.q),\n",
    "                             y=(profile.R), error_y={\n",
    "        \"type\": 'data',\n",
    "        \"array\": (profile.R_e),\n",
    "        \"visible\": True},\n",
    "        name=\"Islatu\"))\n",
    "\n",
    "    if is_log:\n",
    "        fig.update_yaxes(type=\"log\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is kept separate so that one can replot graphs without overwriting the\n",
    "# title.\n",
    "title = \"Bkg Corrections.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the background has been subtracted we can view the current state of\n",
    "# the reflectivity profile.\n",
    "plot_xrr_curve(profile, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, the above plot leaves a lot to be desired. Now it is necessary to \n",
    "# carry out a series of corrections on the data. Firstly, if this data was\n",
    "# acquired using the DCD setup, then we need to specify a DCD normalization\n",
    "# file that will have been collected before this profile.\n",
    "\n",
    "from islatu.corrections import get_interpolator\n",
    "from islatu.io import i07_dat_to_dict_dataframe\n",
    "\n",
    "if is_DCD_data:\n",
    "    itp = get_interpolator(DCD_normalization_file, i07_dat_to_dict_dataframe)\n",
    "    profile.qdcd_normalisation(itp)\n",
    "    title = \"DCD + \" + title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the reflectivity curve after correcting for the DCD q-dependent \n",
    "# incident intensity.\n",
    "if is_DCD_data:\n",
    "    plot_xrr_curve(profile, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make this look a bit more... connected. The reason the XRR curve is\n",
    "# so bumpy at the moment is because the beam attenuation is changing with scan\n",
    "# number. Correcting for attenuation variation between scans will help a lot!\n",
    "\n",
    "# The beam attenuation is stored in the .nxs file that we used to load our \n",
    "# profile, right at the beginning. So, islatu already knows about the \n",
    "# attenuation as a function of scan number! All we need to do is tell islatu\n",
    "# to correct for it, and we're done.\n",
    "\n",
    "profile.transmission_normalisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping this separate so one can replot the graph without changing the title!\n",
    "title = \"Transmission + \" + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how transmission normalization has affected the curve.\n",
    "plot_xrr_curve(profile, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we need to correct for the fact that, at low Q, only a small fraction\n",
    "# of the beam is incident on the sample surface. At high Q, all of the beam \n",
    "# will be incident on the sample surface. This correction is known as a \n",
    "# footprint correction, and in Islatu this is handled exactly assuming that the\n",
    "# beam has a Gaussian profile.\n",
    "\n",
    "# We will need to specify the fwhm of the beam, in m.\n",
    "beam_FWHM = 100e-6\n",
    "\n",
    "# In I07 the trough is around 20cm long.\n",
    "sample_size = 200e-3\n",
    "\n",
    "# Carry out the footprint correction.\n",
    "profile.footprint_correction(beam_width=beam_FWHM, sample_size=sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the title accordingly.\n",
    "title = \"Footprint + \" + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and plot!\n",
    "plot_xrr_curve(profile, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all necessary corrections have been performed, we need to stitch the \n",
    "# individual scans together to arrive at one single profile. Islatu can do this\n",
    "# automatically with its rebin method.\n",
    " \n",
    "# Rebin our data into 500 equally spaced bins. If you want logarithmically \n",
    "# spaced bins, call like this:   \n",
    "# profile.rebin(..., rebin_as=\"log\", ....)\n",
    "\n",
    "number_of_new_qs = 4000\n",
    "profile.rebin(number_of_q_vectors=number_of_new_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = \"R(Q), Fully Corrected\"\n",
    "# plot_xrr_curve(profile, title=title)\n",
    "\n",
    "tom_processing_path = data_dir + \"processing/\"\n",
    "tom_875 = tom_processing_path + \"404875_refl3b.dat\"\n",
    "\n",
    "# Prepare the figure.\n",
    "fig = go.Figure()\n",
    "\n",
    "arr = np.loadtxt(tom_875)\n",
    "x = arr.T[0]\n",
    "y = arr.T[1]\n",
    "yerr = arr.T[2]\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=y, \n",
    "    error_y = {\"type\":'data', \"array\":yerr, \"visible\":True}, name=\"I07\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=(profile.q), \n",
    "    y=(profile.R), error_y={\n",
    "        \"type\":'data', \n",
    "        \"array\":(profile.R_e),\n",
    "        \"visible\":True},\n",
    "    name=\"Islatu\"))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_yaxes(type=\"log\")\n",
    "\n",
    "fig.update_layout(title='Islatu vs I07',\n",
    "    autosize=False,\n",
    "    width=1000, height=800,\n",
    "    margin=dict(l=65, r=50, b=65, t=90),\n",
    "    xaxis_title = \"q/Å\", yaxis_title = \"R\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profile.R_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM HERE ON CODE IS DEPRECATED; KEPT ONLY FOR INFORMATIONAL PURPOSES.\n",
    "# FROM HERE ON CODE IS DEPRECATED; KEPT ONLY FOR INFORMATIONAL PURPOSES.\n",
    "# FROM HERE ON CODE IS DEPRECATED; KEPT ONLY FOR INFORMATIONAL PURPOSES.\n",
    "# FROM HERE ON CODE IS DEPRECATED; KEPT ONLY FOR INFORMATIONAL PURPOSES.\n",
    "# FROM HERE ON CODE IS DEPRECATED; KEPT ONLY FOR INFORMATIONAL PURPOSES.\n",
    "\n",
    "\n",
    "# Now the image is cropped, it's time to subtract the background. We'll do this\n",
    "# by fitting Gaussians to each of the scattering profiles along x. The constant\n",
    "# offset in the Gaussian fit will be taken to be the background.\n",
    "\n",
    "from islatu.background import fit_gaussian_1d\n",
    "importlib.reload(islatu.background)\n",
    "\n",
    "\n",
    "# It isn't necessary to save the value of the optimized fitting parameters to \n",
    "# use Islatu. Here we're keeping track of the popts to check if our Gaussian\n",
    "# fits look sensible.\n",
    "popts = profile.bkg_sub(fit_gaussian_1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets plot the Gaussians and check the fits!\n",
    "from islatu.background import univariate_normal\n",
    "\n",
    "# Scan and image numbers of interest.\n",
    "scan_number = 5\n",
    "img_number = 5\n",
    "\n",
    "# Prepare the figure.\n",
    "title = \"Scan {}, Image {}\".format(scan_number, img_number)\n",
    "fig = go.Figure().update_layout(title=title)\n",
    "\n",
    "# Get the Gaussian fit parameters from the scan of interest.\n",
    "# popt is: <mean>, <sigma>, <offset>, <factor>.\n",
    "popt = popts[scan_number][img_number][0]\n",
    "\n",
    "# Get the image array for the scan of interest.\n",
    "arr = get_image_array(scan_number, img_number)\n",
    "\n",
    "arr_along_x = np.mean(arr, axis=0)\n",
    "\n",
    "# Create x-axes\n",
    "pixels = np.arange(x_end-x_start)\n",
    "pseudo_pixels = np.arange(0,  x_end - x_start, 0.05)\n",
    "\n",
    "# Generate the Gaussian with optimal fitting parameters.\n",
    "gauss_opt = univariate_normal(pseudo_pixels, *popt)\n",
    "\n",
    "arr_along_x = np.sqrt(arr_along_x)\n",
    "gauss_opt = np.sqrt(gauss_opt)\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=pixels, y=arr_along_x))\n",
    "fig.add_trace(go.Scatter(x=pseudo_pixels, y=gauss_opt, line=dict(dash='dot')))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we've plotted a single Gaussian. Now lets plot all the fits in one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: this cell is for use in the auto cropping module.\n",
    "\n",
    "# This gives us the rough location of the peak, but really we want a little more\n",
    "# detailed information. Lets use scipy's find_peaks function to extract some \n",
    "# additional info.\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Specifying the prominence of the peak allows us to filter out signal peaks \n",
    "# from noise.\n",
    "prominence = (0.1, None)\n",
    "x_peaks, properties = find_peaks(raw_frame_x_mean, prominence=prominence)\n",
    "y_peaks, properties = find_peaks(raw_frame_y_mean, prominence=prominence)\n",
    "\n",
    "# Prepare the figures as before\n",
    "fig, axs = plt.subplots(4, 1)\n",
    "\n",
    "axs[0].plot(raw_frame_x_mean)\n",
    "axs[1].plot(raw_frame_y_mean)\n",
    "axs[2].plot(raw_frame_x_mean)\n",
    "axs[3].plot(raw_frame_y_mean)\n",
    "\n",
    "# The following is deprecated, for use with matplotlib\n",
    "figure(figsize=(20, 10), dpi=80)\n",
    "\n",
    "# Label the peaks\n",
    "axs[0].plot(x_peaks, raw_frame_x_mean[x_peaks], \"x\")\n",
    "axs[1].plot(y_peaks, raw_frame_y_mean[y_peaks], \"x\")\n",
    "\n",
    "for i, x_val in enumerate(x_peaks):\n",
    "    axs[0].annotate(x_val, (x_val, raw_frame_x_mean[x_val]))\n",
    "\n",
    "for i, x_val in enumerate(y_peaks):\n",
    "    axs[1].annotate(x_val, (x_val, raw_frame_y_mean[x_val]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to crop the image such that the peaks shown above are a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
